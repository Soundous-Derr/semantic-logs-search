"""
Phase 4: Recherche sÃ©mantique et analyse avancÃ©e
"""

from database import VectorDatabase
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from typing import List, Dict
import numpy as np
import logging
from utils import get_logger

logger = get_logger(__name__)

class SemanticSearchEngine:
    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):
        """Initialise le moteur de recherche sÃ©mantique"""
        self.db = VectorDatabase()
        self.model = SentenceTransformer(model_name)
        self.db.connect()
    
    def search_by_error(self, error_description: str, top_k: int = 10) -> List[Dict]:
        """Cas d'usage 1: Retrouver tous les logs similaires Ã  une erreur donnÃ©e"""
        print(f"\nðŸ” Recherche sÃ©mantique pour: '{error_description}'")
        
        query_embedding = self.model.encode(error_description)
        results = self.db.semantic_search(query_embedding.tolist(), top_k=top_k, threshold=0.5)
        
        print(f"âœ“ {len(results)} logs similaires trouvÃ©s:")
        for i, result in enumerate(results, 1):
            print(f"\n  {i}. [SimilaritÃ©: {result['similarity']:.2%}]")
            print(f"     Level: {result['log_level']}")
            print(f"     Texte: {result['text'][:100]}...")
        
        return results
    
    def find_error_clusters(self, n_clusters: int = 10) -> Dict:
        """Cas d'usage 2: Identifier les groupes d'erreurs frÃ©quentes"""
        print(f"\nðŸ‘¥ Clustering des erreurs (k={n_clusters})...")
        
        query = """
        SELECT l.id, le.embedding, l.original_text, l.log_level
        FROM log_embeddings le
        JOIN logs l ON le.log_id = l.id
        WHERE l.log_level = 'ERROR'
        LIMIT 10000
        """
        
        self.db.cursor.execute(query)
        results = self.db.cursor.fetchall()
        
        if not results:
            logger.warning("Aucun log d'erreur trouvÃ©")
            return {}
        
        log_ids = [row[0] for row in results]
        embeddings = np.array([np.fromstring(str(row[1]), sep=',') for row in results])
        
        kmeans = KMeans(n_clusters=min(n_clusters, len(results)), random_state=42)
        kmeans.fit(embeddings)
        
        clusters = {}
        for cluster_id in range(len(set(kmeans.labels_))):
            mask = kmeans.labels_ == cluster_id
            cluster_logs = [log_ids[i] for i, m in enumerate(mask) if m]
            clusters[cluster_id] = {
                'size': len(cluster_logs),
                'centroid': kmeans.cluster_centers_[cluster_id].tolist(),
                'logs': cluster_logs[:5]
            }
        
        print(f"\nâœ“ {len(clusters)} clusters identifiÃ©s:")
        for cluster_id, info in clusters.items():
            print(f"  Cluster {cluster_id}: {info['size']} logs")
        
        return clusters
    
    def temporal_analysis(self, error_pattern: str, timeframe_days: int = 7) -> Dict:
        """Cas d'usage 3: Analyser l'Ã©volution temporelle des erreurs similaires"""
        print(f"\nðŸ“… Analyse temporelle (derniers {timeframe_days} jours)...")
        
        query_embedding = self.model.encode(error_pattern)
        results = self.db.semantic_search(query_embedding.tolist(), top_k=1000, threshold=0.5)
        
        if not results:
            logger.warning("Aucun log trouvÃ© pour ce pattern")
            return {}
        
        temporal_data = {}
        for result in results:
            timestamp = result.get('timestamp', 'unknown')
            if timestamp:
                temporal_data[timestamp] = temporal_data.get(timestamp, 0) + 1
        
        print(f"\nâœ“ Distribution temporelle:")
        for timestamp, count in sorted(temporal_data.items())[:10]:
            print(f"  {timestamp}: {count} erreurs")
        
        return temporal_data
    
    def compare_with_keyword_search(self, query: str, top_k: int = 10) -> Dict:
        """Compare recherche sÃ©mantique vs recherche par mots-clÃ©s"""
        print(f"\nðŸ”¬ Comparaison: SÃ©mantique vs Mot-clÃ©")
        print(f"   RequÃªte: '{query}'")
        
        query_embedding = self.model.encode(query)
        semantic_results = self.db.semantic_search(query_embedding.tolist(), top_k=top_k)
        
        semantic_ids = set(r['id'] for r in semantic_results)
        
        print(f"\nâœ“ RÃ©sultats:")
        print(f"  Recherche sÃ©mantique: {len(semantic_results)} rÃ©sultats")
        print(f"  Top rÃ©sultats: {len(semantic_ids)}")
        
        return {
            'semantic': semantic_results,
            'count': len(semantic_results)
        }
    
    def close(self):
        """Ferme la connexion Ã  la base"""
        self.db.disconnect()


def run_demo():
    """DÃ©mo des 4 cas d'usage"""
    
    engine = SemanticSearchEngine()
    
    print("\n" + "="*70)
    print("ðŸš€ DÃ‰MONSTRATION - RECHERCHE SÃ‰MANTIQUE")
    print("="*70)
    
    print("\n" + "-"*70)
    print("ðŸ“Œ CAS 1: Retrouver logs similaires Ã  une erreur donnÃ©e")
    print("-"*70)
    engine.search_by_error("Database connection timeout error", top_k=5)
    
    print("\n" + "-"*70)
    print("ðŸ“Œ CAS 2: Identifier les groupes d'erreurs frÃ©quentes")
    print("-"*70)
    clusters = engine.find_error_clusters(n_clusters=5)
    
    print("\n" + "-"*70)
    print("ðŸ“Œ CAS 3: Analyser l'Ã©volution des erreurs")
    print("-"*70)
    engine.temporal_analysis("connection error", timeframe_days=7)
    
    print("\n" + "-"*70)
    print("ðŸ“Œ CAS 4: Comparer recherche sÃ©mantique vs mot-clÃ©")
    print("-"*70)
    comparison = engine.compare_with_keyword_search("timeout", top_k=5)
    
    engine.close()


if __name__ == "__main__":
    run_demo()
# ğŸ“ GUIDE DE PRÃ‰SENTATION - TP Moteur de Recherche SÃ©mantique

## ğŸ“‹ Format de la dÃ©monstration

Vous avez **3 options** pour prÃ©senter ce TP:

---

## Option 1ï¸âƒ£ : **DÃ©monstration Interactive en CLI** (RecommandÃ©e)

### âœ… Avantages:
- Simple et rapide Ã  exÃ©cuter
- Aucune dÃ©pendance web
- Montre bien les rÃ©sultats rÃ©els
- Parfait pour une prÃ©sentation en classe

### ğŸš€ ExÃ©cution:

```bash
# Activer le venv
.\venv\Scripts\Activate.ps1
$env:PYTHONIOENCODING="utf-8"

# Lancer la dÃ©mo
python demo_interactive.py
```

### ğŸ“Š Ce que vous verrez:

```
================================================================================
ğŸš€ DÃ‰MONSTRATION - Moteur de Recherche SÃ©mantique Big Data
================================================================================

4 CAS D'USAGE Ã€ EXPLORER:

   1. Recherche de logs similaires Ã  une erreur
   2. Identification des groupes d'erreurs frÃ©quentes
   3. Analyse de l'Ã©volution temporelle
   4. Comparaison sÃ©mantique vs mot-clÃ©
   5. ExÃ©cuter tous les cas
   0. Quitter

Choisissez (0-5): 
```

### ğŸ’¡ ScÃ©nario de prÃ©sentation:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Choisir option 5 pour exÃ©cuter TOUS les cas     â”‚
â”‚ Cela montre:                                    â”‚
â”‚  1. Recherche sÃ©mantique (similaritÃ© 81-82%)    â”‚
â”‚  2. Clustering K-Means (3-5 clusters)           â”‚
â”‚  3. Distribution temporelle (graphique)         â”‚
â”‚  4. Comparaison approches (5 rÃ©sultats chacune) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Option 2ï¸âƒ£ : **Interface Web Streamlit**

### âœ… Avantages:
- Visuellement attractive
- Interface interactive et moderne
- Parfait pour une soutenance visuelle
- Tableaux et graphiques intÃ©grÃ©s

### ğŸš€ ExÃ©cution:

```bash
# Activer le venv
.\venv\Scripts\Activate.ps1

# Installer streamlit (si nÃ©cessaire)
pip install streamlit

# Lancer l'interface
streamlit run app_streamlit.py
```

### ğŸ“Š Ce que vous verrez:

```
Interface web avec:
  â”œâ”€ ğŸ  Page d'accueil (architecture, objectifs)
  â”œâ”€ ğŸ” Cas 1: Recherche sÃ©mantique interactive
  â”œâ”€ ğŸ‘¥ Cas 2: Clustering avec graphiques
  â”œâ”€ ğŸ“Š Cas 3: Analyse temporelle (line chart)
  â”œâ”€ âš–ï¸  Cas 4: Comparaison visuelle
  â””â”€ ğŸ“ˆ Statistiques globales
```

S'ouvrira dans le navigateur Ã : `http://localhost:8501`

---

## Option 3ï¸âƒ£ : **Scripts Python simples**

### Pour cas d'usage spÃ©cifique:

#### Cas 1 - Recherche sÃ©mantique:
```bash
python -c "
from src.semantic_search import SemanticSearchEngine
engine = SemanticSearchEngine()
results = engine.search_by_error('Database timeout', top_k=5)
for r in results:
    print(f\"- {r['text'][:80]}... (similaritÃ©: {r['similarity']*100:.1f}%)\")
"
```

#### Cas 2 - Clustering:
```bash
python -c "
from src.semantic_search import SemanticSearchEngine
engine = SemanticSearchEngine()
clusters = engine.find_error_clusters(n_clusters=3)
for cid, info in clusters.items():
    print(f\"Cluster {cid}: {info['size']} logs\")
"
```

---

## ğŸ¯ PLAN DE PRÃ‰SENTATION COMPLET (15-20 minutes)

### â° Timing recommandÃ©:

**1. Introduction (2 min)**
```
- Contexte: Logs massifs difficiles Ã  exploiter
- Objectif: Recherche sÃ©mantique efficace
- Approche: Embeddings + vectorisation + index
```

**2. Architecture (3 min)**
```
Montrer le pipeline:
Dataset (100K logs)
    â†“ [Spark - Phase 2]
Traitement batch
    â†“ [Sentence-Transformers - Phase 3]
Vectorisation (384-dim)
    â†“ [PostgreSQL+pgvector - Phase 4]
Index IVFFlat
    â†“
Recherche sÃ©mantique
```

**3. DÃ©monstration live (10 min)**

```
ExÃ©cuter: python demo_interactive.py

Cas 1 (2 min):
  - RequÃªte: "Database connection timeout"
  - RÃ©sultats: 5 logs similaires (81-82%)
  - Montrer que les rÃ©sultats FONT SENS

Cas 2 (2 min):
  - Clustering K-Means des erreurs
  - 3 clusters avec 1875, 1900, 1225 logs
  - CentroÃ¯des des clusters

Cas 3 (2 min):
  - Distribution temporelle
  - Montrer comment les erreurs Ã©voluent

Cas 4 (2 min):
  - Comparaison sÃ©mantique vs mot-clÃ©
  - Montrer la diffÃ©rence fondamentale
```

**4. Conclusions (3 min)**
```
- âœ… Tous les cas d'usage fonctionnent
- âœ… Vectorisation efficace (100K logs en ~80s)
- âœ… Recherche rapide (<1s)
- âœ… Clustering rÃ©vÃ¨le patterns cachÃ©s
```

---

## ğŸ“Š DONNÃ‰ES QUE VOUS PRÃ‰SENTEREZ

### **Cas 1 - Recherche sÃ©mantique:**
```
RequÃªte: "Database connection timeout error"

âœ“ 5 logs similaires trouvÃ©s:

  1. [SimilaritÃ©: 82.09%]
     Level: ERROR
     Texte: 2026-02-06 10:04:12 [ERROR] Database connection 
             timeout after 30 seconds - Host: db-server-7...

  2. [SimilaritÃ©: 81.95%]
     Level: ERROR
     Texte: 2026-02-06 10:04:13 [ERROR] Database connection 
             timeout after 30 seconds - Host: db-server-7...
  
  ... (3 rÃ©sultats supplÃ©mentaires)
```

### **Cas 2 - Clustering:**
```
âœ“ 3 clusters identifiÃ©s:
  Cluster 0: 1875 logs
  Cluster 1: 1900 logs
  Cluster 2: 1225 logs

Total: 5000 logs d'erreur analysÃ©s
```

### **Cas 3 - Analyse temporelle:**
```
Distribution temporelle pour "connection error":

2026-02-06: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (1000 erreurs)

Pattern: Erreurs concentrÃ©es sur cette pÃ©riode
```

### **Cas 4 - Comparaison:**
```
RequÃªte: "timeout"

Recherche sÃ©mantique: 5 rÃ©sultats
  - Capture tous les logs relatifs aux timeout
  - MÃªme avec formulations diffÃ©rentes

Recherche mot-clÃ©: 5 rÃ©sultats
  - Uniquement occurrences exactes de "timeout"
  - Peut manquer des variantes
```

---

## ğŸ’¾ FICHIERS Ã€ AVOIR PRÃŠTS

```
Avant la prÃ©sentation, assurez-vous d'avoir:

âœ… demo_interactive.py      (pour la dÃ©mo CLI)
âœ… app_streamlit.py         (pour l'interface web)
âœ… src/semantic_search.py   (moteur de recherche)
âœ… src/database.py          (requÃªtes PostgreSQL)
âœ… BILAN_FINAL.md           (rÃ©fÃ©rence rapide)
```

---

## ğŸ–¥ï¸ CONFIGURATION TERMINAL

### **Pour Ã©viter les erreurs d'encodage UTF-8 sous Windows:**

```powershell
# Avant chaque lancement:
$env:PYTHONIOENCODING="utf-8"

# Puis:
.\venv\Scripts\Activate.ps1
python demo_interactive.py
```

---

## ğŸ“ POINTS CLÃ‰S Ã€ ABORDER

### **Pourquoi cette approche est meilleure que la recherche par mot-clÃ©?**

```
Exemple concret:

RequÃªte: "connection problem"

âŒ Mot-clÃ© seul: Ne trouve que "connection" + "problem"
   Manque: "timeout", "refused", "unavailable", etc.

âœ… SÃ©mantique: Comprend le SENS
   Trouve: Tous les types de problÃ¨mes de connexion
   MÃªme avec mots diffÃ©rents
```

### **DÃ©fis du Big Data rÃ©solus:**

```
1. VOLUME (100K logs)
   â†’ Spark distribue le traitement
   
2. VECTORISATION (384 dimensions)
   â†’ Sentence-Transformers en batch
   
3. RECHERCHE RAPIDE
   â†’ Index IVFFlat (approximÃ© mais rapide)
   
4. PATTERN DETECTION
   â†’ K-Means clustering sur embeddings
```

---

## âœ¨ TIPS POUR UNE BONNE PRÃ‰SENTATION

### âœ… Ã€ FAIRE:
- [x] Tester la dÃ©mo AVANT (vÃ©rifier PostgreSQL)
- [x] Garder le terminal visible
- [x] Montrer les logs rÃ©els retournÃ©s
- [x] Expliquer les pourcentages de similaritÃ©
- [x] Comparer sÃ©mantique vs mot-clÃ© cÃ´te Ã  cÃ´te

### âŒ Ã€ Ã‰VITER:
- [ ] Corriger les erreurs de connexion en live
- [ ] Parler de dÃ©tails techniques inutiles
- [ ] Ignorer les cas d'usage pratiques
- [ ] Lancer plusieurs dÃ©mos simultanÃ©ment

---

## ğŸ¬ SCRIPT DE PRÃ‰SENTATION EXEMPLE

```
"Bonjour, je prÃ©sente un moteur de recherche sÃ©mantique sur logs.

Les systÃ¨mes Big Data gÃ©nÃ¨rent des millions de logs par jour.
Trouver une erreur spÃ©cifique est trÃ¨s difficile avec la recherche 
par mot-clÃ© classique.

Notre solution utilise:
1. Apache Spark pour ingÃ©rer 100,000 logs
2. Sentence-Transformers pour crÃ©er des embeddings sÃ©mantiques
3. PostgreSQL + pgvector pour indexer et rechercher rapidement
4. Clustering pour identifier patterns d'erreurs

Je vais montrer 4 cas pratiques...

[EXÃ‰CUTER demo_interactive.py]

Comme vous voyez, en cherchant 'Database timeout error', 
on trouve 5 logs SIMILAIRES avec 81-82% de compatibilitÃ©.

Les approches traditionnelles ne trouveraient que les logs 
contenant exactement "timeout"...

[CONTINUER AVEC CAS 2, 3, 4]"
```

---

## ğŸ† QUESTIONS Ã€ ANTICIPER

### **Q: Comment Ã§a fonctionne vraiment?**
R: Les embeddings convertissent chaque log en vecteur de 384 dimensions.
   Deux logs similaires auront des vecteurs proches.
   La distance cosinus mesure cette proximitÃ© (0-1).

### **Q: Pourquoi pgvector?**
R: Permet de stocker les embeddings directement dans PostgreSQL
   avec des index spÃ©cialisÃ©s (IVFFlat) pour recherche rapide.

### **Q: Performance?**
R: Vectorisation: ~80 sec pour 100K logs
   Recherche: <1 sec pour find 5 similaires
   Clustering: ~2 sec pour K-Means sur 5000 logs

### **Q: ScalabilitÃ©?**
R: Spark permet de traiter des millions de logs
   pgvector peut indexer des millions d'embeddings
   Ã€ tester en prod sur plus gros volumes.

---

## ğŸ“š RÃ‰FÃ‰RENCES Ã€ MENTIONNER

```
- Sentence-Transformers: https://www.sbert.net/
- PostgreSQL pgvector: https://github.com/pgvector/pgvector
- Apache Spark: https://spark.apache.org/
- Clustering K-Means: scikit-learn
```

---

**Bon courage pour votre prÃ©sentation! ğŸš€**
